---
date created: 2021-10-19 19:12:20 (+03:00), Tuesday
---

# Урок 6: Сетевые абстракции. Probes [youtube](https://www.youtube.com/watch?v=OmTYdf_uDeQ)

## Освежаем знания по базовым абстракциям [00:00:16](https://youtu.be/OmTYdf_uDeQ?t=16)
### Pod
- В kubernetes минимальная абстракция - это не контейнер, а pod
- Pod может состоять минимум из 2х контейнеров
    - один контейнер - это непосредственно рабочая нагрузка, внутри запущено наше приложение
    - второй контейнер - так называемый служебный контейнер, он держит в себе сетевой неймспейс, [процесс pause](https://stackoverflow.com/questions/48651269/what-are-the-pause-containers), его мы особо не касаемся на практике
- Более того, сама абстракция pod тоже служебная, запуская свое приложение с помощью пода мы ставим себя в очень неудобное положение, т.к. лишаем себя гибкости а также двух важных вещей в контексте управления приложением:
    - первое - это обновление приложения, допустим, у нас вышла новая версия приложения, нам нужно каким-то образом сделать рестарт пода, чтобы он пересоздался, и на уровне пода это неудобно
    - второе - это уменьшение/увеличение количества реплик то есть скейлинг - все приходится делать вручную, это неудобно
- Таким образом, pod это служебная абстракция, на её уровень приходится спускаться, когда дело касается какого-то дебага, например, посмотреть логи

### ReplicaSet [00:03:16](https://youtu.be/OmTYdf_uDeQ?t=196)
- Эта абстракция с помощью которой достаточно удобно можно приложение скейлить
- На уровне репликасетов мы можем удобно, централизовано, с помощью одной команды увеличивать и уменьшать количество реплик одного приложения, это здорово, это хорошо и решает одну из двух таких ключевых задач по управлению нашим приложением - скейлинг
- Но с помощью репликасетов неудобно обновлять наше приложение, нам приходится все равно руками как-то там лезть, в общем неудобно, поэтому репликасетами мы тоже не пользуемся, это тоже, скорее, служебная абстракция, ею пользуемся наверное еще реже даже чем подом, потому что это прям совсем такая служебная-служебная, отвечает она только за управление скейлингом

### Deployment [00:04:17](https://youtu.be/OmTYdf_uDeQ?t=257)
- Это действительно та абстракция с помощью которой можно запускать приложение, это действительно так, потому что deployment решает две вот эти самые задачи управления приложением - управления репликами и обновления вашего приложения, все можно делать с помощью деплоймента, всё описывается в yaml манифесте, всё управляется с помощью kubectl, всё достаточно удобно

## Про вступление [00:04:45](https://youtu.be/OmTYdf_uDeQ?t=285)
- Вот это небольшое вступление к теме было нужно, потому что помимо этих двух задач, обновление приложения и скейлинг, есть еще ряд задач, которые не менее важны
- Одна из этих задач - это понимать, а действительно ли приложение которое сейчас запущено в кластере, оно работает и с ним все хорошо
    - Это очень хороший вопрос, очень важный вопрос, нам нужно понимать что действительно, трафик, который идет на наше приложение, он там обрабатывается и с ним всё хорошо
- Может быть такое чисто технически, что приложение висит, процесс как бы есть, он с PID 1 где-то в контейнере крутится, но по факту функциональность не осуществляется, то есть приложение не работает, это может быть случай, например, какого нибудь дедлока, и чтобы такие моменты контролировать kubernetes нам предлагает такое решение как пробы, это возможность как раз понимать, что происходит с приложением, действительно ли оно работает, действительно ли оно готово принимать трафик и действительно ли оно запустилось
- Для такого контроля у нас есть три вида этих проб - это лайвнес проба, рединес проба и стартап проба

## Probes [00:07:09](https://youtu.be/OmTYdf_uDeQ?t=429)
- Синоним хелсчеков
- Позволяют проверять, что приложение действительно работает

### Liveness Probe [00:07:19](https://youtu.be/OmTYdf_uDeQ?t=439)
- Контроль за состоянием приложения во время его жизни
- Исполняется постоянно, с заданной периодичностью
- Если такая проверка будет провалена, то приложение (под) будет перезапущено

### Readiness Probe [00:08:06](https://youtu.be/OmTYdf_uDeQ?t=486)
- Проверяет, готово ли приложение применять трафик
- В случае неудачного выполнения приложение убирается из балансировки, соответственно, после этого в данный инстанс приложения перестанет идти трафик
- Исполняется постоянно, с заданной периодичностью

### Startup Probe [00:09:10](https://youtu.be/OmTYdf_uDeQ?t=550)
- Проверяет, запустилось ли приложение вообще
- Исполняется при старте, остальные типы проверок начнут выполнятся после завершения проверки данного типа

### Переходим в консоль [00:14:07](https://youtu.be/OmTYdf_uDeQ?t=847)
- Работаем в каталоге `~/school-dev-k8s/practice/7.network-abstractions/1.probes`
- Смотрим манифест деплоймента:
```yaml
---
# file: practice/1.kube-basics-lecture/4.resources-and-probes/deployment-with-stuff.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - image: quay.io/testing-farm/nginx:1.12
        name: nginx
        ports:
        - containerPort: 80
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 80
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 80
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
          initialDelaySeconds: 10
        startupProbe:
          httpGet:
            path: /
            port: 80
          failureThreshold: 30
          periodSeconds: 10
        resources:
          requests:
            cpu: 10m
            memory: 100Mi
          limits:
            cpu: 100m
            memory: 100Mi
...
```
- Probes описываются в спецификации внутри контейнеров
- Для каждого контейнера своё описание probes
- Рассматриваем настройки probes
    - readinessProbe
        - failureThreshold
            - допустимое количество проваленных попыток подряд, прежде чем приложение будет выведено из балансировки
            - применяется для того, чтобы из-за каких-то небольших проблем, например с сетью, приложение не останавливалось полностью
        - httpGet
            - сама проверка, в данном случае мы идём в корневой локейшн нашего приложения по 80 порту, для проверки, что nginx готов принимать трафик, этого достаточно
            - успешными считаются коды ответа в диапазоне от 200 до 399
                - например, 301 - это ОК, а 400, 404 - уже не ОК
            - помимо httpGet есть еще проверки:
                - exec
                    - с помощью неё мы можем выполнить внутри контейнера какую-то команду, например, если это база данных, мы можем выполнить SELECT 1, таким образом убедиться, что БД поднялась и готова принимать запросы
                - tcpSocket
                    - это самая простая проверка, которая позволяет проверять TCP сокет, стучаться в него, если он открыт и работает - значит проверка прошла, всё ОК
        - periodSeconds
            - означает, с какой периодичностью выполнять проверку
        - successThreshold
            - сколько успешных проверок сбросит счётчик failureThreshold
        - timeoutSeconds
            - ограничение на время выполнения проверки, собственно, таймаут
    - livenessProbe
        - большинство настроек аналогичны описанным выше
        - initialDelaySeconds
            - отсрочка выполнения первой проверки, использовали до появления startupProbe
    - startupProbe
        - основное отличие от предыдущих проверок - большие значения, т.е. мы даём сервису 5 минут на запуск
- При выводе k get pod, в колонке READY выводится результат readinessProbe
- Если сходить в логи пода, развёрнутого из этого манифеста деплоймента, можно увидеть информацию о запросах probes к нашему nginx

## Способы публикации [00:28:32](https://youtu.be/OmTYdf_uDeQ?t=1712)
- Как опубликовать приложение, запущенное в кластере kubernetes, чтобы клиенты, находящиеся вне кластера, могли получить к нему доступ?
- Как настроить внутрикластерное взаимодействие своих приложений, фронтенда, бэкенда?
- Унас есть 2 абстракции, с помощью которых можно решать данные задачи, о них ниже

### Service [00:29:23](https://youtu.be/OmTYdf_uDeQ?t=1763)
- Ключевые моменты почти для всех сервисов
    - Важно, чтобы селектор совпадал с лейблами подов
    - Поды и сервисы должны находиться в одном неймспейсе
- ClusterIP [00:29:42](https://youtu.be/OmTYdf_uDeQ?t=1782)
    - Используется для того, чтобы наладить внутрикластерное взаимодействие частей приложения (например, связать фронтенд с бэкендом)
    - В теории, можно отказаться от использования данного сервиса и работать с IP адресами подов, передавать их, например, через переменые окружения, но это будет работать до тех пор, пока поды не начнут перезапускаться и, соответственно, менять адреса
    - Также, с помощью данного сервиса мы можем пробрасывать приложение через kubectl port-forward на хост, с которго запускается данная команда, это удобно для разработки или отладки. Таким образом удобно работать с зависимостями, можно обращаться к тем компонентам кластера, которые требуются в данный момент
        - Команда `kubectl port-forward service/my-service 10000:80` пробросит 80 порт сервиса my-service на 10000 порт хоста, с которого запускается эта команда
        - Раньше подобное можно было делать командой kubectl proxy, но сейчас этот метод считается устаревшим
- NodePort [00:34:22](https://youtu.be/OmTYdf_uDeQ?t=2062)
    - [Документация](https://kubernetes.io/docs/concepts/services-networking/service/#nodeport)
    - Позволяет опубликовать приложение наружу, для этого он и используется, правда, с оговорками
    - Может публиковать приложение только на определённом диапазоне портов, по умолчанию это 30000-32767
    - При необходимости можно явно указать нужный порт в манифесте
    - Создаёт на каждой ноде кластера соответствующее правило трансляции
    - Подходит для использования, если есть внешний балансировщик, в котором можно указать соответствие
    - Может использоваться для работы с LoadBalancer [00:38:09](https://youtu.be/OmTYdf_uDeQ?t=2289)
- LoadBalancer [00:38:20](https://youtu.be/OmTYdf_uDeQ?t=2300)
    - Много всего сказано, основная идея - всё будет работать хорошо в облаках
- ExternalName
    - Позволяет создать алиас для DNS имени в качестве имени сервиса
- ExternalIPs
    - 
- Headless (стоит в стороне от основное)

### Ingress