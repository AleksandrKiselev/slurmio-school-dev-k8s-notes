---
date created: 2021-10-07 19:00:18 (+03:00), Thursday
---
# Урок 3: Абстракции приложения. Вечерняя школа «Kubernetes для разработчиков» [youtube](https://www.youtube.com/watch?v=LLVfC08UVqY)

- Разбираемся с replicaset и deployment
- Бонусом Resources: как правильно работать с ресурсами кластера

# Ответы на вопросы из чата:
- 1
    - Q:  Кто такой Developer Advocate, кого от кого он защищает, чем занимается
    - A: Это публичное лицо, которое представляет комьюнити для компании и наоборот. Посредник между продуктами компании и пользователями, комьюнити. Защищает разработчиков, инженеров и всех прочих людей в IT от незнания, это такое связующее звено между комьюнити какой-то технологии и компанией, группой-разработчиков, которые эту технологию предоставляют. В данном случае, Павел выступает посредником между тем, что он с коллегами делает внутри своей компании (MSC), теми продуктами, которые выходят на рынок и комьюнити пользователей этих продуктов. Одна из его задач - доносить способы пользоваться продуктами так, чтобы было хороши и пользователям и компании-провайдеру, чтобы ни у кого по ночам ничего не горело. С точки зрения комьюнити задача Developer Advocate - доносить то что думает комьюнити относительно продукта до product owner'ов, директоров, конечных разработчиков и т.д., всех людей продукта в команде 
- 2
    - Q: По поводу сказанного о портах, что директивы в YAML файле являются фактически документацией
    - A: Аналогии на стримах могут упрощать реальную картину мира. В примере с портами было сказано, что если указывть в yaml файле пода порты - то это не более чем документирование и ни на что более не влияет. На самом деле кое на что влияет, если зайти на под и выполнить там команду env, можно увидеть большое количество прокинутых переменных окружения, если описывать в поде этот порт, то kubernetes будет генерить и добавлять для других подов соответствующую переменную окружения. Это сделано для сервис дискавери, но в реальности этим практически никто не пользуется. Основная мысль - могут быть опущены детали, которые сильно усложнят понимание для новичков за счёт потока ненужной на первоначальном этапе информации. При этом, ведущие стараются не врать а говорить исходя из сложившихся практик, например, в данном случаче, бОльшей правдой является, что описание порта нужно для документирования, а не то, что приложение будет работать с ним. Это один из примеров, такие упрощения еще будут встречаться

По поводу споров насчёт того, можно ли под рассматривать как процесс, скорее контейнер можно рассматривать как процесс, а под - как неделимый инстанс приложения, а кубер это ОС, которая всем этим рулит, да это тоже упрощение, метафора

В прошлый раз мы остановлись на том, что запустили под с приложением, узнали что если нам нужно 2 экземпляра приложения, то нам придется отредактировать файл с описанием пода, переименовать под, т.к. в одном пространстве имён не может быть 2х одинаковых сущностей одного типа, и непосредственно создать его из этого файла, пришли к выводу, что это совсем не удобно, а в kubernetes есть более удобные способы масштабировать приложения, чем поды.

# ReplicaSet (вставить сюда ссылку на слайд)
- Это объект, который представляет из себя набор реплик приложения
- В общем и целом внутри yaml описания ReplicaSet содержится темплейт описания подов, которые будут создаваться
- При создании подов будут проставляться специальные метки, ярлыка (label) на поды, по которым ReplicaSet будет определять, что это именно его поды
- У самого ReplicaSet есть информация о селекторе, т.е. он знает, его поды это те, которые удовлетворяют этому селектору
- Содержит поле, указывающее, сколько мы хотим создать подов из нашего темплейта

# Практика
- git must have, если есть пробелы - можно пройти бесплатный курс от слёрма (вставить ссылку)
- работаем с каталогом ~/school-dev-k8s/practice/2.application-abstractions/2.replicaset
- replicaset.yaml выглядит так:

```yaml
---
# file: practice/2.application-abstractions/2.replicaset/replicaset.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: my-replicaset
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - image: quay.io/testing-farm/nginx:1.12
        name: nginx
        ports:
        - containerPort: 80
...
```
- у ReplicaSet, так же как и у пода, так же как и у всего в kubernetes структура описания это yaml
- как и у всех объектов в kubernetes у него есть тип - kind и версия api (поднималость в первом уроке)
- обращаем внимание, что у пода версия апи была v1, у ReplicaSet стабильная версия это apps/v1
- тип, как ни странно, ReplicaSet
- информацию о типах и всякое такое можно узнать в документации, на сайте kubectl.io
- далее будет лайфак, где брать нужную инфу по kubernetes прямо из консоли
- также как у пода, у ReplicaSet есть metadata, там мы указываем имя
- аналогично, spec - специализация нашего объекта
- отличительные относительно пода параметры ReplicaSet:
    - replicas - количество реплик нашего приложения, подов с одним и тем же описанием, мы хотим запустить
    - селектор (selector), в данном описании видно, что мы выбираем все поды с меткой `app: my-app`
    - темплейт (template)
        - содержит описание пода, при этом имя пода не указывается, т.к. оно будет генерироваться автоматически
        - в метаданных содержит label, соответствующий селектору
        - spec
            - такой же как в описанити пода
            - имена контейнеров нужно указывать, в отличие от имён подов в темплейтах, причём имена в рамках пода должны быть уникальны
            - описание портов - для документации (но не совсем, как было сказано выше)

# По темплейтам
- pod это абстракция, которая хоть и является минимальной единицей, с которой умеет работать kubernetes, но в реальности мы почти никогда не создаём поды напрямую, потому что это неудобно. Можно считать pod полуслужебной абстракцией kubernetes.
- Т.к. мы не хотим работать с каждым подом отдельно, мы хотим описать темплейт пода и дальшей сказать kubernetes с помощью ресурса ReplicaSet "создай N подов"

# По лейблам
- Они могут быть присвоены вообще любому объекту, например, мы можем присвоить метку и самому ReplicaSet
- Почему лейблы это хорошо
    - kubernetes сам их использует, например, чтобы понимать, какие поды привязаны к каким ReplicaSet
    - по ним можно понимать, что за приложение, мы можем навешать кастомных человекочитаемых меток и по ним ориентироваться
    - инструменты для работы с kubernetes, тот же kubectl get, позволяют фильтровать, например, kubectl get pod -l "app=myapp" выдаст поды с соответствующей меткой
- Рекомендуется везде проставлять и использовать лейблы, особенно в рамках курса, далее будут достаточно сложные, приближенные к реальности, конфигурации, там везде будут лейблы

# Возвращаемся к консоли
чистим за собой с прошлого раза:
```shell
kubectl delete pod --all # удаляем все поды
kubectl delete replicaset --all # удаляем все репликасеты
```
\<sarcasm>лайфхак для разработчиков с рут доступом к проду, которые хотят порадовать своих коллег из эксплуатации:
```shell
kubectl delete all --all -A # пройтись по всем неймспейсам и удалить все объекты со всеми именами, аналог rm -rf
```
\</sarcasm>
# Разница между create и apply
- create - команда, которая выполняется только 1 раз, второй раз выдаст ошибку
- apply
    - применяет изменения, идемпотентна, т.е. создат то чего нет, если всё уже есть и соответствует описанию - ничего не сделает, если есть расхождения в описании и реальности, исправит их
    - можно указывать для аргумента -f не только файл но и директорию
    - обычно используется в пайплайнах CI/CD
создаём (аплаим) репликасет:
```shell
kubectl apply -f replicaset.yaml
```
запросим информацию по ReplicaSet, используем сокращение rs:
```shell
kubectl get rs
```
получим:
```shell
NAME            DESIRED   CURRENT   READY   AGE
my-replicaset   2         2         2       2m25s
```
- DESIRED - сколько мы указывали создавать реплик
- CURRENT - сколько по факту есть
- READY - цифра 2 показывает что 2 пода сейчас работают и доступны. Что конкретно это значит, будет разбираться позже, т.к. затрагивает сетевые абстракции

Проверяем поды:
```shell
kubectl get po
```
выдаст нам что-то вроде:
```shell
NAME                  READY   STATUS              RESTARTS   AGE
my-replicaset-g8lc4   0/1     ContainerCreating   0          88s
my-replicaset-n7bxt   0/1     ContainerCreating   0          88s
```
- замечаем, что поды называются по имени ReplicaSet + некий кусок хэша, это сделано во избежание попыток создания одноимённых однотипных сущностей
если мы посмотрим на детальную информацию по одному из подов:
```shell
k describe pod my-replicaset-g8lc4 # если не указать имя пода, то получим информацию о всех подах
```
то сможем увидеть строку `Labels:       app=my-app`
можем запросить информацию о подах с указанием этой метки:
```shell
kubectl get po -l "app=my-app"
```
вывод будет аналогичен тому что был выше, т.к. других подов пока нет
# Про self-healing
- Репликасет призван поддерживать нужное количество реплик, независимо от внешних обстоятелств, пока явно не указано другое, например, если уборщица выгнав вас из-за стола случайно введёт команду удаления пода или одна из нод кластера выйдет из строя, на свободных ресурсах будет выполнена попытка запустить недостающий под в репликасете.


Например, удаляем под и с небольшой задержкой снова запрашиваем информацию:
```shell
kubectl delete pod my-replicaset-g8lc4
kubectl get po -l "app=my-app"
```
получаем
```shell
NAME                  READY   STATUS    RESTARTS   AGE
my-replicaset-hnwjp   1/1     Running   0          65s # это уже новый под
my-replicaset-n7bxt   1/1     Running   0          16m
```

# Про скейлинг (масштабирование):
- 1 способ - открыть наш yaml файл и исправить там количество реплик и выполнить аплай изменений
- 2 способ - kubectl scale. Данным способом можно как добавлять так и убирать целевое количество реплик
- При скейлинге вниз одним из ключевых критериев является возраст пода, первыми будут удаляться самые молодые поды, т.е. созданные позже
Пример со 2м способом:
```shell
kubectl scale --replicas 3 rs my-replicaset
kubectl get po -l "app=my-app"
```
получим такую картину:
```shell
NAME                  READY   STATUS              RESTARTS   AGE
my-replicaset-hnwjp   1/1     Running             0          12m
my-replicaset-n6v8r   0/1     ContainerCreating   0          13s
my-replicaset-n7bxt   1/1     Running             0          28m
```
В кластере есть ограничения, 4 пода на неймспейс (пользователя?)
# Про автокомплит
- Павел рекомендует настроить автокомплит для kubectl и тем самым облегчить себе жизнь
- Для zshell есть отдельный плагин kubectl
- Для чистого bash есть kubectl completion, можно вывести справку командой ubectl completion -h, там всё описано

# Экспериментируем с подом
## Пример 1
- проверяем теорию о том, что кластер автоматически прибъет под, созданный руками, но с такой же меткой, как в ReplicaSet
- берём конфиг из предыдущего урока и добавляем туда :
```yaml
---
# file: practice/2.application-abstractions/1.pod/pod.yaml
apiVersion: v1
kind: pod
metadata:
  name: my-pod
  labels:
    app: my-app # добавили метку как в ReplicaSet
spec:
  containers:
  - image: quay.io/testing-farm/nginx:1.12
    name: nginx
    ports:
    - containerPort: 80
...
```
применяем, проверяем:
```shell
k apply -f pod.yaml
k get po
```
видим:
```shell
NAME                  READY   STATUS        RESTARTS   AGE
my-pod                0/1     Terminating   0          4s  # видим, что свежесозданный под удаляется
my-replicaset-hnwjp   1/1     Running       0          55m
my-replicaset-n7bxt   1/1     Running       0          70m
```
- Теория работает, ReplicaSet, который отслеживает какие поды его и сколько их, по метке my-app, увидел что в этом неймспейсе появился ещё один под с таким же лейблом, он посчитал его лишним и прибил, это нормальное явление.
- Обычно в реальности именно так не делают, но может произойти так, что подов в репликасете будет больше чем ожидалось, например, при выходе из строя ноды кластер через какое-то время перестанет считать приложения на этой ноде работающими, даже если они фактически работают, например, если нода упала не полностью, а отказали только некоторые компоненты. Кластер для себя пометит такие поды как недоступные и создаст новые, на доступных нодах, согласно описанию ReplicaSet. По возвращении ноды в строй может так сложиться, что мы получим больше подов чем указано в описании ReplicaSet, тогда подам на вернувшейся ноде будет отправлен сигнал на уничтожение

## Пример 2
- Обновление приложения
- Допустим, мы собрали новый докер образ и хотим заменить им старый
- Мы можем увидеть в описании теплейта для ReplicaSet, что в названии образа (пути к образу?) содержится тег с версией, в нашем случае 1.12, допустим, мы хотим обновиться до 1.13
- Самый очевидный сопосов - поправить файл с описанием и выполнить apply, делать так мы конечно не будем
- Другой способ - использовать команду ниже:
 ```shell
 kubectl set image replicaset my-replicaset nginx=quay.io/testing-farm/nginx:1.13
 ```
 - В шаблоне пода может быть несколько контейнеров, поэтому мы должны указать, для какого именно мы меняем образ
 - Не забываем, что учебном кластере не стоит работать с докерхабом, т.к. это исчерпает лимиты на подключения, поэтому используем другие репозитории, в данном случае quay.io
 - Т.к. в данном случае у нас всего один контейнер, мы можем сократить команду, это часто используется в простых пайплайнах:
 ```shell
 kubectl set image replicaset my-replicaset '*=quay.io/testing-farm/nginx:1.13'
 ```
 - Если после этого выполнить k describe rs, увидим, что указана новая версия образа
 - Если мы выполним k describe po, увидим что контейнеры живы уже давно и версия образа указана старая. Так происходит, потому что командами выше мы меняем темплейт, а задача ReplicaSet - отслеживать количество подов по метке. Для реального обновления версии в поде мы можем начать прибивать существующие поды, тогда новые будут созданы с версией образа из шаблона
 - Вывод - ReplicaSet не решает задачу обновления приложения но...

# Deployment (вставить ссылку на презентацию)
- Это более высокоуровневая абстракция над ReplicaSet
- Позволяет решать проблему обновления приложения
- Когда мы создаём Deployment, он создаёт под собой ReplicaSet, а он создаёт под собой поды в нужном количестве
- Если мы меняем версию образа в Deployment, он создаёт новый ReplicaSet и с помощью Rolling Update или стратегии Recreate передеплоивается и у нас появляется приложение новой версии в нашем кластере kubernetes

# Очень сложно, ничего непонятно, идём в консоль
чистим за собой:
```shell
kubectl delete replicaset --all # удаляем все репликасеты
```
- При удалении верхнеуровневой абстракции все относящиеся к ней объекты абстракций более низкого уровня удаляются автоматически

меняем директорию:
```shell
cd ../3.deployment/
```

# Вопросы
Кресло?
- |
    - Q: Можно ли указывать количество реплик при скейлинге через арифметические вычисления, наприер `kubectl scale --replicas +3 rs my-replicaset`
    - A: kubectl такое не умеет, средствами bash и т.п. традиционно можно (сначала получаем через get, обрабатываем и формируем нужную команду)
- |
    - Q: Что будет при скейлинге вниз с работой, выполняемой подом, завершится, прервётся, будет выполнять другой под
    - A: Ответить на вопрос нам поможет kubectl explain
        - например, kubectl explain pod выдаст информацию о всех верхнеуровневых полях для pod
        - отвечая на вопрос
            - нужно заглянуть в spec пода, выполняем kubectl explain pod.spec
            - находим описание параметра terminationGracePeriodSeconds и читаем
            - это поле можно указать в подах, шаблонах ReplicaSet или Deployment, оно говорит о следующем:
                - когда завершается приложение в контейнере, приложению отправляется sigterm, т.е. мы просим его корректно (gracefully) завершиться.
                    - terminationGracePeriodSeconds указывает, сколько секунд даётся на эти операции, по умолчанию 30 секунд
                    - Если приложение так умеет, то оно принимает sigterm, обрабатывает оставшиеся запросы или другую работу и после этого самостоятельно корректно завершается
                    - Если приложение не умеет обрабатывать sigterm, то оно завершается сразу же, все обрабатываемые им запросы прерываются, есть ряд техник для обработки таких ситуаций (press stop хуки, возможно об этом будет позже)
                    - Если приложение на sigterm не реагирует, то через заданное в terminationGracePeriodSeconds время ему будет отправлена команда sigkill, т.е. оно будет мгновенно завершено
- |
    - Q: Шелл у Павла (в чате есть ответы)
    - A: 

# Возвращаемся к консоли и работаем с Deployment
- заглянем в yaml файл в нашей директории, видим следующее:
```yaml
---
# file: practice/2.application-abstractions/3.deployment/deployment.yaml
apiVersion: apps/v1 # видим что версия API такая же как у ReplicaSet
kind: Deployment # Соответствующий нашей теме тип
metadata:
  name: my-deployment
spec: # описание идентичное описанию предыдущего ReplicaSet
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - image: quay.io/testing-farm/nginx:1.12
        name: nginx
        ports:
        - containerPort: 80
...
```
- почти то же что и ReplicaSet, но есть отличия в поведении

Применяем наше описание и смотрим что получилось:
```shell
kubectl apply -f deployment.yaml
k get deploy
```
видим:
```shell
NAME            READY   UP-TO-DATE   AVAILABLE   AGE
my-deployment   2/2     2            2           81s
```
смотрим поды:
```shell
k get po
```
видим:
```shell
NAME                             READY   STATUS    RESTARTS   AGE
my-deployment-79788cc48d-bnqr7   1/1     Running   0          2m32s
my-deployment-79788cc48d-qfnkp   1/1     Running   0          2m31s
```
Видим особенности отличий именования подов ReplicaSet от подов Deployment

если  посмотрим теперь на ReplicaSetы, то увидим
```shell
NAME                       DESIRED   CURRENT   READY   AGE
my-deployment-79788cc48d   2         2         2       5m13s
```
- Итого, Deployment создал нам ReplicaSet, сгенерировал ему имя на базе имени деплоймента и создал 2 пода в этом ReplicaSet, везде добавляя кусочки хэшей
- Хэши считаются от содержимого того, что мы применяем, возможно зависит ещё от кластера, тут Павел не уверен, можно поискать информацию отдельно
- Совет из практики - не нужно помогать kubernetes вручную, например, у нас есть Deployment, не нужно пытаться скейлить ReplicaSet или добавлять/удалять поды напрямую, с бОльшей вероятностью это навредит а не поможет, лучше искать корневую причину проблем, которые заставляют вас делать такое, а kubernetes сам справится со своими задачами
- Обновляем образ в Deployment, также как в ReplicaSet:
    - через правку yaml и apply
    - командой `set image deployment my-deployment '*=quay.io/testing-farm/nginx:1.13'`
    - 3й способ - редактирование ресурса на лету с помощью kubectl edit, например:

```shell
kubectl edit deployment my-deployment
```
- данная команда вызовет редактор по умолчанию и позволит редактировать именно объект в кластере, т.е. мы просим кластер прислать нам полное описание указанного деплоймента, который вот прям щас в кластере запущен, далее, кластер нам его прислал, kubectl открыл нам его в редакторе и когда мы внесём и сохраним изменения, эти изменения попадут не в какой-то локальный файл, а сразу отправится обратно в кластер kubernetes и там применится
- это удобный способ быстро экспериментировать, дебажить, выстрелить себе в ногу, и т.п., но совсем не хороший способ работать с production кластером, особенно, если вы работаете с ним не один, а с коллегами, т.к. данные изменения трудно отследить
- по хорошему, нужно работать через yaml файлы описаний, git, apply через CI/CD, желательно еще тестами обвязать и вот это вот всё

- при работе через edit мы видим множество полей, которые мы сами не создавали, это все доступные поля для данного объекта и в них указаны значения по умолчанию для данного кластера
- после изменения версии образа nginx опросив поды мы видим похожую картину:
```shell
NAME                             READY   STATUS              RESTARTS   AGE
my-deployment-79788cc48d-bnqr7   1/1     Running             0          29m
my-deployment-79788cc48d-qfnkp   0/1     Terminating         0          29m
my-deployment-d7fcf87f9-vztvm    1/1     Running             0          19s
my-deployment-d7fcf87f9-zk4tq    0/1     ContainerCreating   0          3s
```
- т.е. старые поды удаляются, а новые создаются, по идентификаторам можно догадаться, что у нас поменялся ReplicaSet
- если запросим информацию по ReplicaSet, то увидим:
```shell
NAME                       DESIRED   CURRENT   READY   AGE
my-deployment-79788cc48d   0         0         0       33m  # старый, ненужный ReplicaSet
my-deployment-d7fcf87f9    2         2         2       3m53s
```
- Далее Павел демонстрирует шаги, которые происходят, при изменениях в Deployment, а именно:
    - У нас есть один ReplicaSet, где указана старая версия образа, запущено ожидаемое количество подов, в нашем случае 2
    - Создаётся новый ReplicaSet с новой версией образа, ожидаемое количество подов указано как 0
    - Далее происходит постепенный скейлинг обоих реплик, в нашем примере с шагом 1, т.е. у нас будет 2/0, затем 1/1, затем 0/2 подов со старой и новой версиями образа соответственно
# Остановился тут:
https://youtu.be/LLVfC08UVqY?list=PL8D2P0ruohOBSA_CDqJLflJ8FLJNe26K-&t=5035

# Из чата:
GitHub - ahmetb/kubectl-aliases: Programmatically generated handy kubectl aliases.